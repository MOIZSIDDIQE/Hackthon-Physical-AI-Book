---
title: 8.2.2 Sensor Systems and Integration Implementation
sidebar_position: 38
---

# 8.2.2 Sensor Systems and Integration Implementation

## Learning Objectives

- Implement sensor drivers and communication interfaces for humanoid robots
- Develop multi-sensor fusion algorithms for state estimation
- Integrate sensor systems with real-time control frameworks
- Apply calibration techniques for sensor accuracy improvement
- Validate sensor system performance in real-world scenarios

## Introduction

The practical implementation of sensor systems for humanoid robots requires careful integration of hardware interfaces, real-time processing algorithms, and communication protocols. Unlike theoretical sensor models, practical implementations must handle timing constraints, noise, communication delays, and hardware limitations. This section provides detailed implementation strategies for integrating diverse sensor modalities into cohesive perception systems that enable robust humanoid robot operation.

Real-world sensor implementation involves multiple challenges including data synchronization across different sampling rates, handling sensor failures gracefully, managing computational resources efficiently, and ensuring safety in dynamic environments. The implementation approach must balance accuracy, reliability, and computational efficiency to meet the demanding requirements of humanoid robot applications.

Modern sensor system implementations leverage specialized hardware, optimized algorithms, and robust software architectures to achieve the performance required for dynamic humanoid operation. The integration of machine learning techniques with traditional signal processing enables more sophisticated perception capabilities while maintaining the reliability required for safe human-robot interaction.

## 2. Hardware Interface Implementation

### 2.1 Sensor Driver Development

Sensor drivers provide the fundamental interface between hardware sensors and software applications. Proper driver implementation ensures reliable data acquisition and system stability.

```python
import threading
import time
import numpy as np
from abc import ABC, abstractmethod
from typing import Dict, List, Tuple, Optional
import serial
import can
from dataclasses import dataclass

@dataclass
class SensorData:
    """Generic sensor data structure with timestamp and validity"""
    timestamp: float
    data: np.ndarray
    validity: bool = True
    source_id: str = ""

class SensorDriver(ABC):
    """Abstract base class for sensor drivers"""

    def __init__(self, sensor_id: str, config: Dict):
        self.sensor_id = sensor_id
        self.config = config
        self.is_connected = False
        self.data_buffer = []
        self.lock = threading.Lock()

    @abstractmethod
    def connect(self) -> bool:
        """Establish connection to sensor hardware"""
        pass

    @abstractmethod
    def read_data(self) -> Optional[SensorData]:
        """Read raw data from sensor"""
        pass

    @abstractmethod
    def disconnect(self) -> bool:
        """Disconnect from sensor hardware"""
        pass

class EncoderDriver(SensorDriver):
    """Driver for rotary encoders with position and velocity sensing"""

    def __init__(self, sensor_id: str, config: Dict):
        super().__init__(sensor_id, config)
        self.position = 0.0
        self.velocity = 0.0
        self.last_position = 0.0
        self.last_time = time.time()
        self.encoder_resolution = config.get('resolution', 4096)
        self.is_absolute = config.get('is_absolute', False)

    def connect(self) -> bool:
        """Connect to encoder via specified interface (SPI, I2C, etc.)"""
        try:
            # Initialize communication interface based on config
            interface_type = self.config.get('interface', 'spi')

            if interface_type == 'spi':
                import spidev
                self.spi = spidev.SpiDev()
                self.spi.open(self.config['bus'], self.config['device'])
            elif interface_type == 'i2c':
                import smbus2
                self.i2c = smbus2.SMBus(self.config['bus'])
            elif interface_type == 'serial':
                self.serial_port = serial.Serial(
                    port=self.config['port'],
                    baudrate=self.config['baudrate'],
                    timeout=self.config.get('timeout', 1.0)
                )

            self.is_connected = True
            return True
        except Exception as e:
            print(f"Encoder connection failed: {e}")
            return False

    def read_data(self) -> Optional[SensorData]:
        """Read encoder position and calculate velocity"""
        if not self.is_connected:
            return None

        try:
            # Read raw encoder value
            raw_value = self._read_raw_encoder()

            if raw_value is not None:
                # Convert to position in radians
                position = (raw_value / self.encoder_resolution) * 2 * np.pi

                # Calculate velocity using numerical differentiation
                current_time = time.time()
                dt = current_time - self.last_time

                if dt > 0:
                    velocity = (position - self.last_position) / dt
                else:
                    velocity = 0.0

                # Update stored values
                self.position = position
                self.velocity = velocity
                self.last_position = position
                self.last_time = current_time

                # Pack data into SensorData structure
                data = np.array([position, velocity])
                return SensorData(
                    timestamp=current_time,
                    data=data,
                    validity=True,
                    source_id=self.sensor_id
                )

        except Exception as e:
            print(f"Encoder read error: {e}")
            return SensorData(
                timestamp=time.time(),
                data=np.array([self.position, self.velocity]),
                validity=False,
                source_id=self.sensor_id
            )

    def _read_raw_encoder(self) -> Optional[int]:
        """Read raw encoder value from hardware interface"""
        try:
            interface_type = self.config.get('interface', 'spi')

            if interface_type == 'spi':
                # Send command to read encoder position
                response = self.spi.xfer2([0x00, 0x00])  # Example SPI command
                raw_value = (response[0] << 8) | response[1]
            elif interface_type == 'i2c':
                # Read from I2C register
                raw_bytes = self.i2c.read_i2c_block_data(
                    self.config['address'], 0x00, 2
                )
                raw_value = (raw_bytes[0] << 8) | raw_bytes[1]
            elif interface_type == 'serial':
                # Read from serial interface
                line = self.serial_port.readline().decode().strip()
                raw_value = int(line) if line.isdigit() else None

            return raw_value

        except Exception as e:
            print(f"Raw encoder read error: {e}")
            return None

    def disconnect(self) -> bool:
        """Close communication interface"""
        try:
            interface_type = self.config.get('interface', 'spi')

            if hasattr(self, 'spi'):
                self.spi.close()
            elif hasattr(self, 'i2c'):
                self.i2c.close()
            elif hasattr(self, 'serial_port'):
                self.serial_port.close()

            self.is_connected = False
            return True
        except Exception as e:
            print(f"Encoder disconnect error: {e}")
            return False

class IMUDriver(SensorDriver):
    """Driver for Inertial Measurement Units (IMU)"""

    def __init__(self, sensor_id: str, config: Dict):
        super().__init__(sensor_id, config)
        self.accelerometer_bias = np.zeros(3)
        self.gyroscope_bias = np.zeros(3)
        self.magnetometer_bias = np.zeros(3)
        self.temperature = 0.0
        self.sample_rate = config.get('sample_rate', 100)  # Hz

    def connect(self) -> bool:
        """Connect to IMU via I2C, SPI, or serial interface"""
        try:
            interface_type = self.config.get('interface', 'i2c')

            if interface_type == 'i2c':
                import smbus2
                self.i2c = smbus2.SMBus(self.config['bus'])
                self.address = self.config['address']

                # Initialize IMU (example for MPU6050)
                self.i2c.write_byte_data(self.address, 0x6B, 0x00)  # Wake up device
                self.i2c.write_byte_data(self.address, 0x1A, 0x03)  # Set DLPF
                self.i2c.write_byte_data(self.address, 0x1C, 0x08)  # Set accelerometer range
                self.i2c.write_byte_data(self.address, 0x1B, 0x08)  # Set gyroscope range

            elif interface_type == 'spi':
                import spidev
                self.spi = spidev.SpiDev()
                self.spi.open(self.config['bus'], self.config['device'])

            self.is_connected = True
            return True

        except Exception as e:
            print(f"IMU connection failed: {e}")
            return False

    def read_data(self) -> Optional[SensorData]:
        """Read IMU data (accelerometer, gyroscope, magnetometer)"""
        if not self.is_connected:
            return None

        try:
            # Read raw IMU data
            raw_data = self._read_raw_imu()

            if raw_data is not None:
                # Apply bias corrections and scaling
                accel_raw, gyro_raw, mag_raw, temp_raw = raw_data

                # Convert raw values to physical units
                accel = self._convert_accel(accel_raw)
                gyro = self._convert_gyro(gyro_raw)
                mag = self._convert_magnetometer(mag_raw)
                temp = self._convert_temperature(temp_raw)

                # Apply bias corrections
                accel_corrected = accel - self.accelerometer_bias
                gyro_corrected = gyro - self.gyroscope_bias
                mag_corrected = mag - self.magnetometer_bias

                # Pack all data into single array
                combined_data = np.concatenate([accel_corrected, gyro_corrected, mag_corrected, [temp]])

                current_time = time.time()
                self.temperature = temp

                return SensorData(
                    timestamp=current_time,
                    data=combined_data,
                    validity=True,
                    source_id=self.sensor_id
                )

        except Exception as e:
            print(f"IMU read error: {e}")
            return SensorData(
                timestamp=time.time(),
                data=np.zeros(10),  # 3 accel + 3 gyro + 3 mag + 1 temp
                validity=False,
                source_id=self.sensor_id
            )

    def _read_raw_imu(self) -> Optional[Tuple]:
        """Read raw IMU values from hardware"""
        try:
            interface_type = self.config.get('interface', 'i2c')

            if interface_type == 'i2c':
                # Read accelerometer data
                accel_bytes = self.i2c.read_i2c_block_data(self.address, 0x3B, 6)
                accel_raw = np.array([
                    self._twos_complement((accel_bytes[0] << 8) | accel_bytes[1], 16),
                    self._twos_complement((accel_bytes[2] << 8) | accel_bytes[3], 16),
                    self._twos_complement((accel_bytes[4] << 8) | accel_bytes[5], 16)
                ])

                # Read gyroscope data
                gyro_bytes = self.i2c.read_i2c_block_data(self.address, 0x43, 6)
                gyro_raw = np.array([
                    self._twos_complement((gyro_bytes[0] << 8) | gyro_bytes[1], 16),
                    self._twos_complement((gyro_bytes[2] << 8) | gyro_bytes[3], 16),
                    self._twos_complement((gyro_bytes[4] << 8) | gyro_bytes[5], 16)
                ])

                # Read magnetometer data (if available)
                try:
                    mag_bytes = self.i2c.read_i2c_block_data(self.address, 0x03, 6)
                    mag_raw = np.array([
                        self._twos_complement((mag_bytes[0] << 8) | mag_bytes[1], 16),
                        self._twos_complement((mag_bytes[2] << 8) | mag_bytes[3], 16),
                        self._twos_complement((mag_bytes[4] << 8) | mag_bytes[5], 16)
                    ])
                except:
                    mag_raw = np.zeros(3)  # Magnetometer not available

                # Read temperature
                temp_bytes = self.i2c.read_i2c_block_data(self.address, 0x41, 2)
                temp_raw = self._twos_complement((temp_bytes[0] << 8) | temp_bytes[1], 16)

                return accel_raw, gyro_raw, mag_raw, temp_raw

        except Exception as e:
            print(f"Raw IMU read error: {e}")
            return None

    def _twos_complement(self, val: int, bits: int) -> int:
        """Convert from two's complement representation"""
        if val >= 2**(bits-1):
            return val - 2**bits
        return val

    def _convert_accel(self, raw_values: np.ndarray) -> np.ndarray:
        """Convert raw accelerometer values to g's"""
        # Scale factor depends on accelerometer range setting
        scale_factor = 2.0 / 32768.0  # For ±2g range
        return raw_values * scale_factor

    def _convert_gyro(self, raw_values: np.ndarray) -> np.ndarray:
        """Convert raw gyroscope values to rad/s"""
        # Scale factor depends on gyroscope range setting
        scale_factor = 250.0 / 32768.0 * np.pi / 180.0  # For ±250°/s range
        return raw_values * scale_factor

    def _convert_magnetometer(self, raw_values: np.ndarray) -> np.ndarray:
        """Convert raw magnetometer values to μT"""
        # Scale factor for magnetometer (example for HMC5883L)
        scale_factor = 0.92  # For ±1.3 Gauss range
        return raw_values * scale_factor

    def _convert_temperature(self, raw_value: int) -> float:
        """Convert raw temperature value to Celsius"""
        return 25.0 + (raw_value + 12412.0) / 340.0  # Example conversion

    def disconnect(self) -> bool:
        """Close IMU communication interface"""
        try:
            if hasattr(self, 'i2c'):
                self.i2c.close()
            elif hasattr(self, 'spi'):
                self.spi.close()

            self.is_connected = False
            return True
        except Exception as e:
            print(f"IMU disconnect error: {e}")
            return False
```

### 2.2 Communication Protocol Implementation

```python
class CANBusInterface:
    """Implementation of CAN bus communication for sensor networks"""

    def __init__(self, channel: str = 'can0', bitrate: int = 500000):
        self.channel = channel
        self.bitrate = bitrate
        self.bus = None
        self.message_handlers = {}
        self.is_running = False

    def connect(self) -> bool:
        """Connect to CAN bus interface"""
        try:
            self.bus = can.Bus(channel=self.channel, bustype='socketcan', bitrate=self.bitrate)
            self.is_running = True
            return True
        except Exception as e:
            print(f"CAN bus connection failed: {e}")
            return False

    def send_sensor_data(self, sensor_id: str, data: np.ndarray, msg_type: str = 'sensor') -> bool:
        """Send sensor data over CAN bus"""
        if not self.is_connected():
            return False

        try:
            # Create message ID based on sensor type and ID
            msg_id = self._create_message_id(sensor_id, msg_type)

            # Pack sensor data into CAN message
            data_bytes = self._pack_sensor_data(data)

            # Create and send CAN message
            msg = can.Message(
                arbitration_id=msg_id,
                data=data_bytes,
                is_extended_id=True
            )

            self.bus.send(msg)
            return True

        except Exception as e:
            print(f"CAN send error: {e}")
            return False

    def register_message_handler(self, msg_id: int, handler_func):
        """Register handler function for specific message ID"""
        self.message_handlers[msg_id] = handler_func

    def start_message_loop(self):
        """Start receiving messages in separate thread"""
        self.receive_thread = threading.Thread(target=self._receive_messages)
        self.receive_thread.daemon = True
        self.receive_thread.start()

    def _receive_messages(self):
        """Receive and process incoming CAN messages"""
        while self.is_running:
            try:
                msg = self.bus.recv(timeout=0.1)
                if msg is not None:
                    # Check if we have a handler for this message ID
                    if msg.arbitration_id in self.message_handlers:
                        handler = self.message_handlers[msg.arbitration_id]
                        sensor_data = self._unpack_sensor_data(msg.data)
                        handler(msg.arbitration_id, sensor_data, msg.timestamp)
            except Exception as e:
                print(f"CAN receive error: {e}")

    def _create_message_id(self, sensor_id: str, msg_type: str) -> int:
        """Create CAN message ID based on sensor ID and type"""
        # Use a simple encoding scheme: type (4 bits) + sensor ID (28 bits)
        type_map = {'sensor': 0x1, 'control': 0x2, 'status': 0x3}
        type_code = type_map.get(msg_type, 0x1)

        # Convert sensor ID to numeric code
        sensor_code = hash(sensor_id) & 0x0FFFFFFF  # 28 bits

        return (type_code << 28) | sensor_code

    def _pack_sensor_data(self, data: np.ndarray) -> bytes:
        """Pack sensor data into CAN message format"""
        # Convert numpy array to bytes (little endian)
        if data.dtype == np.float32:
            return data.tobytes()
        else:
            # Convert to float32 for consistent packing
            float_data = data.astype(np.float32)
            return float_data.tobytes()

    def _unpack_sensor_data(self, data_bytes: bytes) -> np.ndarray:
        """Unpack sensor data from CAN message"""
        # Convert bytes back to numpy array
        float_values = np.frombuffer(data_bytes, dtype=np.float32)
        return float_values

    def is_connected(self) -> bool:
        """Check if CAN bus is connected"""
        return self.bus is not None and self.is_running

    def disconnect(self):
        """Disconnect from CAN bus"""
        self.is_running = False
        if self.bus:
            self.bus.shutdown()
            self.bus = None
```

## 3. Multi-Sensor Fusion Algorithms

### 3.1 Extended Kalman Filter Implementation

```python
class ExtendedKalmanFilter:
    """Implementation of Extended Kalman Filter for sensor fusion"""

    def __init__(self, state_dim: int, measurement_dim: int):
        self.state_dim = state_dim
        self.measurement_dim = measurement_dim

        # Initialize state vector (e.g., [position, velocity, orientation, angular_velocity])
        self.x = np.zeros(state_dim)

        # Initialize covariance matrix
        self.P = np.eye(state_dim) * 1000.0  # High initial uncertainty

        # Process noise covariance (tuned based on system dynamics)
        self.Q = np.eye(state_dim) * 0.1

        # Measurement noise covariance (from sensor specifications)
        self.R = np.eye(measurement_dim) * 1.0

    def predict(self, dt: float, control_input: np.ndarray = None):
        """Prediction step of EKF"""
        # State transition model (example for position-velocity system)
        F = self._compute_jacobian_f(self.x, dt)

        # Predict state
        self.x = self._state_transition(self.x, dt, control_input)

        # Predict covariance
        self.P = F @ self.P @ F.T + self.Q

    def update(self, measurement: np.ndarray, sensor_type: str = 'imu'):
        """Update step of EKF with measurement"""
        # Compute measurement Jacobian
        H = self._compute_jacobian_h(self.x, sensor_type)

        # Compute innovation
        expected_measurement = self._observation_model(self.x, sensor_type)
        innovation = measurement - expected_measurement

        # Compute innovation covariance
        S = H @ self.P @ H.T + self.R

        # Compute Kalman gain
        try:
            K = self.P @ H.T @ np.linalg.inv(S)
        except np.linalg.LinAlgError:
            # Use pseudo-inverse if S is singular
            K = self.P @ H.T @ np.linalg.pinv(S)

        # Update state
        self.x = self.x + K @ innovation

        # Update covariance
        I = np.eye(self.state_dim)
        self.P = (I - K @ H) @ self.P

    def _state_transition(self, x: np.ndarray, dt: float, u: np.ndarray = None) -> np.ndarray:
        """Non-linear state transition function"""
        # Example: constant velocity model with control input
        # x = [px, py, pz, vx, vy, vz, qw, qx, qy, qz, wx, wy, wz]
        # where p=position, v=velocity, q=quaternion, w=angular velocity

        new_x = x.copy()

        # Update positions based on velocities
        new_x[0:3] = x[0:3] + x[3:6] * dt  # position += velocity * dt

        # For quaternion integration, use quaternion kinematics
        # dq/dt = 0.5 * omega_quat * q
        q = x[6:10]  # quaternion
        omega = x[10:13]  # angular velocity

        # Convert angular velocity to quaternion
        omega_quat = np.array([0, omega[0], omega[1], omega[2]])

        # Quaternion derivative
        q_dot = 0.5 * self._quaternion_multiply(omega_quat, q)

        # Integrate quaternion
        new_q = q + q_dot * dt
        new_q = new_q / np.linalg.norm(new_q)  # Normalize
        new_x[6:10] = new_q

        # Angular velocities may change based on dynamics
        if u is not None:
            # Apply control input (simplified)
            new_x[10:13] = x[10:13] + u * dt

        return new_x

    def _compute_jacobian_f(self, x: np.ndarray, dt: float) -> np.ndarray:
        """Compute Jacobian of state transition function"""
        F = np.eye(self.state_dim)

        # Position-velocity relationships
        F[0:3, 3:6] = np.eye(3) * dt  # Partial derivatives of position w.r.t. velocity

        # Add quaternion kinematics Jacobian (simplified)
        # This is a complex non-linear relationship that would require full derivation
        # For simplicity, we'll use a basic approximation

        return F

    def _observation_model(self, x: np.ndarray, sensor_type: str) -> np.ndarray:
        """Non-linear observation function"""
        if sensor_type == 'accelerometer':
            # Return expected accelerometer reading based on state
            # This includes gravity and linear acceleration
            gravity = np.array([0, 0, -9.81])

            # Convert body-frame acceleration to world frame using rotation matrix
            R = self._quaternion_to_rotation_matrix(x[6:10])
            expected_accel = R.T @ gravity  # Gravity in body frame

            # Add linear acceleration if available in state
            if len(x) > 6:
                expected_accel += x[3:6]  # Add linear acceleration

            return expected_accel

        elif sensor_type == 'gyroscope':
            # Return expected gyroscope reading (angular velocity)
            if len(x) >= 13:
                return x[10:13]  # Angular velocity from state
            else:
                return np.zeros(3)

        elif sensor_type == 'magnetometer':
            # Return expected magnetometer reading (magnetic field in body frame)
            # Assuming Earth's magnetic field in world frame
            mag_world = np.array([22000, 0, 44000])  # Example magnetic field vector

            # Convert to body frame
            R = self._quaternion_to_rotation_matrix(x[6:10])
            expected_mag = R.T @ mag_world

            return expected_mag

        else:
            # Default: return part of state vector
            return x[0:self.measurement_dim]

    def _compute_jacobian_h(self, x: np.ndarray, sensor_type: str) -> np.ndarray:
        """Compute Jacobian of observation function"""
        H = np.zeros((self.measurement_dim, self.state_dim))

        if sensor_type == 'accelerometer':
            # Only orientation affects accelerometer readings
            # This is a complex non-linear relationship
            # For simplicity, we'll return a basic Jacobian
            H[0:3, 6:10] = self._compute_accel_jacobian(x)  # Partial w.r.t. quaternion

        elif sensor_type == 'gyroscope':
            # Direct mapping to angular velocity state
            H[0:3, 10:13] = np.eye(3)

        elif sensor_type == 'magnetometer':
            # Only orientation affects magnetometer readings
            H[0:3, 6:10] = self._compute_mag_jacobian(x)  # Partial w.r.t. quaternion

        return H

    def _quaternion_multiply(self, q1: np.ndarray, q2: np.ndarray) -> np.ndarray:
        """Quaternion multiplication"""
        w1, x1, y1, z1 = q1
        w2, x2, y2, z2 = q2

        w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2
        x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2
        y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2
        z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2

        return np.array([w, x, y, z])

    def _quaternion_to_rotation_matrix(self, q: np.ndarray) -> np.ndarray:
        """Convert quaternion to rotation matrix"""
        w, x, y, z = q

        R = np.array([
            [1 - 2*(y**2 + z**2), 2*(x*y - w*z), 2*(x*z + w*y)],
            [2*(x*y + w*z), 1 - 2*(x**2 + z**2), 2*(y*z - w*x)],
            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x**2 + y**2)]
        ])

        return R

    def _compute_accel_jacobian(self, x: np.ndarray) -> np.ndarray:
        """Compute Jacobian of accelerometer observation w.r.t. quaternion"""
        # This is a complex calculation that depends on the full kinematic model
        # For simplicity, returning a zero matrix (would need full derivation)
        return np.zeros((3, 4))

    def _compute_mag_jacobian(self, x: np.ndarray) -> np.ndarray:
        """Compute Jacobian of magnetometer observation w.r.t. quaternion"""
        # Similar to accelerometer, this requires full kinematic derivation
        return np.zeros((3, 4))

class SensorFusionManager:
    """Manager class for coordinating multiple sensor fusion algorithms"""

    def __init__(self):
        self.sensors = {}
        self.fusion_algorithms = {}
        self.state_estimator = ExtendedKalmanFilter(state_dim=13, measurement_dim=9)  # Example: pos, vel, orient, ang_vel
        self.fusion_lock = threading.Lock()

    def register_sensor(self, sensor_id: str, sensor_type: str, topic: str = None):
        """Register a sensor with the fusion manager"""
        self.sensors[sensor_id] = {
            'type': sensor_type,
            'topic': topic,
            'last_update': 0,
            'data': None
        }

    def register_fusion_algorithm(self, algorithm_name: str, algorithm):
        """Register a fusion algorithm"""
        self.fusion_algorithms[algorithm_name] = algorithm

    def process_sensor_data(self, sensor_id: str, data: np.ndarray, timestamp: float):
        """Process incoming sensor data"""
        with self.fusion_lock:
            # Update sensor data
            if sensor_id in self.sensors:
                self.sensors[sensor_id]['data'] = data
                self.sensors[sensor_id]['last_update'] = timestamp

                # Perform fusion based on sensor type
                sensor_type = self.sensors[sensor_id]['type']

                if sensor_type in ['accelerometer', 'gyroscope', 'magnetometer']:
                    # Update EKF with IMU data
                    self.state_estimator.update(data, sensor_type)

                elif sensor_type == 'encoder':
                    # Process encoder data (position/velocity)
                    # May need to transform to global frame
                    pass

                elif sensor_type == 'camera':
                    # Process visual data (feature tracking, etc.)
                    # Could update position estimate based on visual odometry
                    pass

    def get_fused_state(self) -> Dict:
        """Get the current fused state estimate"""
        with self.fusion_lock:
            state = self.state_estimator.x
            covariance = self.state_estimator.P

            return {
                'position': state[0:3],
                'velocity': state[3:6],
                'orientation': state[6:10],  # quaternion
                'angular_velocity': state[10:13],
                'covariance': covariance,
                'timestamp': time.time()
            }
```

### 3.2 Particle Filter Implementation

```python
class ParticleFilter:
    """Implementation of Particle Filter for non-linear/non-Gaussian systems"""

    def __init__(self, state_dim: int, num_particles: int = 1000):
        self.state_dim = state_dim
        self.num_particles = num_particles

        # Initialize particles randomly across state space
        self.particles = np.random.normal(0, 1, (num_particles, state_dim))
        self.weights = np.ones(num_particles) / num_particles

        # Process noise
        self.process_noise = np.eye(state_dim) * 0.1

    def predict(self, dt: float, control_input: np.ndarray = None):
        """Prediction step: propagate particles through motion model"""
        for i in range(self.num_particles):
            # Apply motion model with noise
            self.particles[i] = self._motion_model(self.particles[i], dt, control_input)

            # Add process noise
            noise = np.random.multivariate_normal(np.zeros(self.state_dim), self.process_noise)
            self.particles[i] += noise

    def update(self, measurement: np.ndarray, sensor_type: str, measurement_noise: np.ndarray):
        """Update step: reweight particles based on measurement likelihood"""
        for i in range(self.num_particles):
            # Compute expected measurement for this particle
            expected_measurement = self._observation_model(self.particles[i], sensor_type)

            # Compute likelihood of actual measurement given particle state
            diff = measurement - expected_measurement
            likelihood = self._gaussian_likelihood(diff, measurement_noise)

            # Update weight
            self.weights[i] *= likelihood

        # Normalize weights
        self.weights += 1e-300  # Avoid numerical issues
        self.weights /= np.sum(self.weights)

    def resample(self):
        """Resample particles based on weights to avoid degeneracy"""
        # Systematic resampling
        indices = self._systematic_resample()

        # Resample particles and reset weights
        self.particles = self.particles[indices]
        self.weights = np.ones(self.num_particles) / self.num_particles

    def estimate_state(self) -> np.ndarray:
        """Estimate state as weighted average of particles"""
        return np.average(self.particles, axis=0, weights=self.weights)

    def _motion_model(self, state: np.ndarray, dt: float, control: np.ndarray) -> np.ndarray:
        """Apply motion model to propagate state forward in time"""
        # Example: simple constant velocity model
        new_state = state.copy()

        # Update positions based on velocities
        new_state[0:3] += new_state[3:6] * dt

        # Update orientations based on angular velocities
        if len(state) > 6:
            # Simplified quaternion integration
            q = state[6:9]  # Use 3D rotation vector representation
            omega = state[9:12] if len(state) > 9 else np.zeros(3)

            new_q = q + omega * dt
            new_state[6:9] = new_q

        return new_state

    def _observation_model(self, state: np.ndarray, sensor_type: str) -> np.ndarray:
        """Predict measurement based on state"""
        if sensor_type == 'position':
            # Return position part of state
            return state[0:3]
        elif sensor_type == 'orientation':
            # Return orientation part of state
            return state[6:9] if len(state) > 6 else np.zeros(3)
        else:
            # Default: return full state
            return state

    def _gaussian_likelihood(self, diff: np.ndarray, cov: np.ndarray) -> float:
        """Compute Gaussian likelihood of measurement difference"""
        try:
            # Compute Mahalanobis distance
            inv_cov = np.linalg.inv(cov)
            dist = diff.T @ inv_cov @ diff

            # Compute likelihood
            norm_factor = 1.0 / np.sqrt((2 * np.pi) ** len(diff) * np.linalg.det(cov))
            likelihood = norm_factor * np.exp(-0.5 * dist)

            return max(likelihood, 1e-300)  # Avoid numerical issues
        except:
            # Fallback to simple Gaussian
            return np.exp(-0.5 * np.sum(diff**2))

    def _systematic_resample(self) -> np.ndarray:
        """Systematic resampling algorithm"""
        # Create cumulative distribution
        cumulative = np.cumsum(self.weights)

        # Generate uniform samples
        u = np.linspace(0, 1, self.num_particles + 1)
        u = u[:-1] + np.random.uniform(0, 1/self.num_particles)

        # Find indices corresponding to uniform samples
        indices = np.zeros(self.num_particles, dtype=int)
        i, j = 0, 0
        while i < self.num_particles:
            while cumulative[j] < u[i]:
                j += 1
            indices[i] = j
            i += 1

        return indices
```

## 4. Real-Time Processing Implementation

### 4.1 Sensor Data Pipeline

```python
import asyncio
from collections import deque
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

class SensorDataPipeline:
    """Real-time pipeline for processing sensor data"""

    def __init__(self, max_buffer_size: int = 1000):
        self.max_buffer_size = max_buffer_size
        self.buffers = {}  # Per-sensor buffers
        self.processors = {}  # Per-sensor processors
        self.fusion_manager = SensorFusionManager()
        self.is_running = False
        self.pipeline_thread = None

        # Thread pool for parallel processing
        self.executor = ThreadPoolExecutor(max_workers=4)

    def add_sensor_buffer(self, sensor_id: str, buffer_size: int = None):
        """Add a buffer for a specific sensor"""
        size = buffer_size or self.max_buffer_size
        self.buffers[sensor_id] = deque(maxlen=size)

    def add_sensor_processor(self, sensor_id: str, processor_func):
        """Add a processing function for a specific sensor"""
        self.processors[sensor_id] = processor_func

    def add_sensor_data(self, sensor_id: str, data: SensorData):
        """Add new sensor data to the pipeline"""
        if sensor_id in self.buffers:
            self.buffers[sensor_id].append(data)

            # Process immediately if processor exists
            if sensor_id in self.processors:
                # Submit to thread pool for parallel processing
                future = self.executor.submit(
                    self.processors[sensor_id], sensor_id, data
                )

                # Handle fusion if needed
                self.fusion_manager.process_sensor_data(
                    sensor_id, data.data, data.timestamp
                )

    def start_pipeline(self):
        """Start the real-time processing pipeline"""
        self.is_running = True
        self.pipeline_thread = threading.Thread(target=self._pipeline_loop)
        self.pipeline_thread.daemon = True
        self.pipeline_thread.start()

    def stop_pipeline(self):
        """Stop the real-time processing pipeline"""
        self.is_running = False
        if self.pipeline_thread:
            self.pipeline_thread.join()
        self.executor.shutdown(wait=True)

    def _pipeline_loop(self):
        """Main pipeline processing loop"""
        while self.is_running:
            start_time = time.time()

            # Process each sensor buffer
            for sensor_id, buffer in self.buffers.items():
                if len(buffer) > 0:
                    # Get latest data
                    latest_data = buffer[-1]

                    # Process if not already processed
                    if latest_data.timestamp > getattr(self, f'last_processed_{sensor_id}', 0):
                        # Update fusion manager
                        self.fusion_manager.process_sensor_data(
                            sensor_id, latest_data.data, latest_data.timestamp
                        )

                        # Update last processed time
                        setattr(self, f'last_processed_{sensor_id}', latest_data.timestamp)

            # Maintain target frequency (e.g., 1000 Hz)
            elapsed = time.time() - start_time
            sleep_time = max(0, 0.001 - elapsed)  # 1ms = 1000Hz
            if sleep_time > 0:
                time.sleep(sleep_time)

class MultiRateSensorProcessor:
    """Processor for handling sensors with different update rates"""

    def __init__(self):
        self.sensors = {}  # {sensor_id: {'rate': Hz, 'last_update': time, 'callback': func}}
        self.process_lock = threading.Lock()

    def register_sensor(self, sensor_id: str, update_rate: float, callback_func):
        """Register a sensor with its update rate and processing callback"""
        self.sensors[sensor_id] = {
            'rate': update_rate,
            'callback': callback_func,
            'last_update': 0,
            'period': 1.0 / update_rate if update_rate > 0 else float('inf')
        }

    def process_data(self, sensor_id: str, data: SensorData):
        """Process sensor data according to its rate requirements"""
        if sensor_id not in self.sensors:
            return False

        current_time = time.time()
        sensor_info = self.sensors[sensor_id]

        # Check if enough time has passed since last processing
        if current_time - sensor_info['last_update'] >= sensor_info['period']:
            # Process the data
            with self.process_lock:
                result = sensor_info['callback'](data)

            # Update last processing time
            sensor_info['last_update'] = current_time
            return result

        return False  # Not time to process yet
```

### 4.2 Synchronization and Timing

```python
class SensorSynchronizer:
    """Synchronize data from multiple sensors with different timestamps"""

    def __init__(self, max_delay: float = 0.1):  # 100ms max delay
        self.max_delay = max_delay
        self.sensor_data = {}  # {sensor_id: [(timestamp, data), ...]}
        self.synchronized_callback = None

    def register_synchronized_callback(self, callback_func):
        """Register callback for when synchronized data is available"""
        self.synchronized_callback = callback_func

    def add_sensor_data(self, sensor_id: str, data: np.ndarray, timestamp: float):
        """Add data from a sensor"""
        if sensor_id not in self.sensor_data:
            self.sensor_data[sensor_id] = deque(maxlen=100)  # Keep last 100 samples

        self.sensor_data[sensor_id].append((timestamp, data))

        # Try to synchronize data
        self._try_synchronize(timestamp)

    def _try_synchronize(self, latest_timestamp: float):
        """Attempt to synchronize data from all sensors"""
        # Check if we have data from all sensors within the time window
        current_time = latest_timestamp
        window_start = current_time - self.max_delay

        # Get the most recent data from each sensor within the window
        synchronized_data = {}

        for sensor_id, data_queue in self.sensor_data.items():
            # Find the most recent data within the time window
            recent_data = None
            for ts, data in reversed(data_queue):  # Check from most recent
                if ts <= current_time and ts >= window_start:
                    recent_data = (ts, data)
                    break

            if recent_data is not None:
                synchronized_data[sensor_id] = recent_data
            else:
                # Don't have recent data from this sensor, can't synchronize
                return

        # All sensors have recent data, call synchronized callback
        if len(synchronized_data) == len(self.sensor_data):
            if self.synchronized_callback:
                self.synchronized_callback(synchronized_data, current_time)

    def interpolate_to_time(self, sensor_id: str, target_time: float) -> Tuple[float, np.ndarray]:
        """Interpolate sensor data to a specific time"""
        if sensor_id not in self.sensor_data or len(self.sensor_data[sensor_id]) < 2:
            # Not enough data for interpolation, return the closest
            if self.sensor_data[sensor_id]:
                return self.sensor_data[sensor_id][-1]
            else:
                return target_time, np.array([])

        # Find the two closest timestamps
        data_list = list(self.sensor_data[sensor_id])
        closest_before = None
        closest_after = None

        for i, (ts, data) in enumerate(data_list):
            if ts <= target_time:
                closest_before = (ts, data)
            if ts >= target_time and closest_after is None:
                closest_after = (ts, data)

        if closest_before and closest_after:
            # Linear interpolation
            t_before, data_before = closest_before
            t_after, data_after = closest_after

            if t_after == t_before:
                return target_time, data_before

            alpha = (target_time - t_before) / (t_after - t_before)
            interpolated_data = data_before + alpha * (data_after - data_before)

            return target_time, interpolated_data
        elif closest_before:
            return closest_before
        elif closest_after:
            return closest_after
        else:
            return target_time, np.array([])

class TimestampCorrector:
    """Correct for clock drift and communication delays"""

    def __init__(self):
        self.clock_offsets = {}  # {sensor_id: offset}
        self.drift_rates = {}    # {sensor_id: drift_rate}
        self.last_sync_time = {} # {sensor_id: time}

    def synchronize_clock(self, sensor_id: str, local_time: float, sensor_time: float):
        """Synchronize sensor clock with local clock"""
        offset = sensor_time - local_time

        if sensor_id not in self.clock_offsets:
            self.clock_offsets[sensor_id] = offset
            self.drift_rates[sensor_id] = 0.0
        else:
            # Update with exponential moving average
            alpha = 0.1  # Smoothing factor
            old_offset = self.clock_offsets[sensor_id]
            self.clock_offsets[sensor_id] = alpha * offset + (1 - alpha) * old_offset

            # Calculate drift rate if we have previous sync
            if sensor_id in self.last_sync_time:
                time_diff = local_time - self.last_sync_time[sensor_id]
                offset_diff = offset - old_offset
                self.drift_rates[sensor_id] = offset_diff / time_diff if time_diff > 0 else 0.0

        self.last_sync_time[sensor_id] = local_time

    def correct_timestamp(self, sensor_id: str, sensor_timestamp: float, current_time: float) -> float:
        """Correct sensor timestamp to local time"""
        offset = self.clock_offsets.get(sensor_id, 0.0)
        drift_rate = self.drift_rates.get(sensor_id, 0.0)
        last_sync = self.last_sync_time.get(sensor_id, current_time)

        # Apply drift correction
        time_since_sync = current_time - last_sync
        drift_correction = drift_rate * time_since_sync

        corrected_time = sensor_timestamp - offset - drift_correction
        return corrected_time
```

## 5. Calibration Implementation

### 5.1 Sensor Calibration Algorithms

```python
class SensorCalibrator:
    """Implementation of sensor calibration algorithms"""

    def __init__(self):
        self.calibration_data = {}
        self.calibration_params = {}

    def calibrate_imu(self, imu_driver: IMUDriver, num_samples: int = 1000) -> Dict:
        """Calibrate IMU bias and scale factors"""
        print("Starting IMU calibration. Keep sensor stationary on level surface.")

        raw_data_samples = []

        # Collect stationary samples
        for i in range(num_samples):
            data = imu_driver.read_data()
            if data and data.validity:
                raw_data_samples.append(data.data)  # [ax, ay, az, gx, gy, gz, mx, my, mz, temp]
            time.sleep(0.01)  # 100Hz sampling

        if not raw_data_samples:
            raise ValueError("No valid IMU data collected")

        raw_data = np.array(raw_data_samples)

        # Separate accelerometer, gyroscope, and magnetometer data
        accel_data = raw_data[:, 0:3]
        gyro_data = raw_data[:, 3:6]
        mag_data = raw_data[:, 6:9]

        # Calculate bias (mean of stationary data)
        accel_bias = np.mean(accel_data, axis=0)
        gyro_bias = np.mean(gyro_data, axis=0)
        mag_bias = np.mean(mag_data, axis=0)

        # For accelerometer, calculate scale factor assuming 1g in z-direction
        # (when sensor is level on ground)
        expected_gravity = np.array([0, 0, 9.81])
        actual_gravity_magnitude = np.linalg.norm(accel_bias)
        accel_scale = actual_gravity_magnitude / 9.81 if actual_gravity_magnitude > 0 else 1.0

        # For magnetometer, estimate hard iron distortion
        # (this is a simplified approach - full calibration requires rotation)
        mag_hard_iron = np.mean(mag_data, axis=0)

        calibration_params = {
            'accel_bias': accel_bias,
            'accel_scale': np.array([accel_scale, accel_scale, accel_scale]),
            'gyro_bias': gyro_bias,
            'gyro_scale': np.ones(3),  # Assume no scale error for gyro
            'mag_bias': mag_hard_iron,
            'mag_soft_iron': np.eye(3)  # Simplified - no soft iron correction
        }

        # Apply calibration to driver
        imu_driver.accelerometer_bias = accel_bias
        imu_driver.gyroscope_bias = gyro_bias
        imu_driver.magnetometer_bias = mag_hard_iron

        print(f"IMU calibration completed:")
        print(f"  Accelerometer bias: {accel_bias}")
        print(f"  Gyroscope bias: {gyro_bias}")
        print(f"  Magnetometer bias: {mag_bias}")

        return calibration_params

    def calibrate_camera(self, camera_driver, calibration_board, num_images: int = 50):
        """Calibrate camera intrinsic parameters"""
        import cv2

        # Prepare object points (3D points in real world space)
        objp = np.zeros((calibration_board['corners_per_row'] * calibration_board['corners_per_col'], 3), np.float32)
        objp[:, :2] = np.mgrid[0:calibration_board['corners_per_row'],
                              0:calibration_board['corners_per_col']].T.reshape(-1, 2)
        objp = objp * calibration_board['square_size']  # Scale to real world size

        # Arrays to store object points and image points
        objpoints = []  # 3D points in real world space
        imgpoints = []  # 2D points in image plane

        images_captured = 0
        print(f"Capturing {num_images} calibration images...")

        while images_captured < num_images:
            # Capture image from camera
            ret, frame = camera_driver.read_frame()  # This is pseudo-code - depends on camera implementation
            if not ret:
                continue

            # Convert to grayscale
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Find chessboard corners
            ret, corners = cv2.findChessboardCorners(gray,
                                                    (calibration_board['corners_per_row'],
                                                     calibration_board['corners_per_col']),
                                                    cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)

            if ret:
                # Refine corner locations
                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
                corners_refined = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)

                # Add to lists
                objpoints.append(objp)
                imgpoints.append(corners_refined)

                # Draw and display corners
                frame_with_corners = cv2.drawChessboardCorners(frame,
                                                              (calibration_board['corners_per_row'],
                                                               calibration_board['corners_per_col']),
                                                              corners_refined, ret)

                images_captured += 1
                print(f"Captured {images_captured}/{num_images} calibration images")

        # Perform calibration
        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)

        calibration_params = {
            'camera_matrix': mtx,
            'distortion_coefficients': dist,
            'rotation_vectors': rvecs,
            'translation_vectors': tvecs
        }

        print(f"Camera calibration completed:")
        print(f"  Camera matrix:\n{mtx}")
        print(f"  Distortion coefficients: {dist.flatten()}")

        return calibration_params

    def calibrate_encoder(self, encoder_driver: EncoderDriver, reference_encoder: EncoderDriver = None):
        """Calibrate encoder for position accuracy"""
        # This would involve comparing with a reference encoder or known position
        # For now, we'll implement a basic offset calibration

        # Reset encoder to known position (requires user intervention)
        print("Reset encoder to known zero position and press Enter...")
        input()  # Wait for user to position encoder

        # Read current encoder value as offset
        data = encoder_driver.read_data()
        if data and data.validity:
            current_pos = data.data[0]  # Position is first element
            encoder_driver.position_offset = -current_pos  # Set offset to make current position zero

            print(f"Encoder calibrated. Current offset: {encoder_driver.position_offset}")
            return {'position_offset': encoder_driver.position_offset}
        else:
            raise ValueError("Could not read encoder for calibration")

    def save_calibration(self, params: Dict, filename: str):
        """Save calibration parameters to file"""
        import json

        # Convert numpy arrays to lists for JSON serialization
        serializable_params = {}
        for key, value in params.items():
            if isinstance(value, np.ndarray):
                serializable_params[key] = value.tolist()
            else:
                serializable_params[key] = value

        with open(filename, 'w') as f:
            json.dump(serializable_params, f, indent=2)

    def load_calibration(self, filename: str) -> Dict:
        """Load calibration parameters from file"""
        import json

        with open(filename, 'r') as f:
            params = json.load(f)

        # Convert lists back to numpy arrays
        for key, value in params.items():
            if isinstance(value, list):
                params[key] = np.array(value)

        return params
```

### 5.2 Multi-Sensor Calibration

```python
class MultiSensorCalibrator:
    """Calibrate relationships between multiple sensors"""

    def __init__(self):
        self.transforms = {}  # {sensor_pair: transform_matrix}

    def calibrate_sensor_alignment(self, sensor1_data: List[np.ndarray],
                                 sensor2_data: List[np.ndarray],
                                 sensor1_type: str, sensor2_type: str) -> np.ndarray:
        """Calibrate spatial alignment between two sensors"""

        # This is a simplified approach - real implementation would be more complex
        # depending on the sensor types

        if sensor1_type == 'camera' and sensor2_type == 'imu':
            # For camera-IMU calibration, we need to find the transformation
            # between their coordinate frames
            return self._calibrate_camera_imu(sensor1_data, sensor2_data)
        elif sensor1_type == 'lidar' and sensor2_type == 'camera':
            # For LIDAR-camera calibration
            return self._calibrate_lidar_camera(sensor1_data, sensor2_data)
        elif sensor1_type == 'encoder' and sensor2_type == 'imu':
            # For encoder-IMU calibration (typically involves mounting positions)
            return self._calibrate_encoder_imu(sensor1_data, sensor2_data)
        else:
            # Generic calibration using iterative closest point or similar
            return self._calibrate_generic(sensor1_data, sensor2_data)

    def _calibrate_camera_imu(self, camera_data: List[np.ndarray],
                            imu_data: List[np.ndarray]) -> np.ndarray:
        """Calibrate transformation between camera and IMU coordinate frames"""
        # This is a simplified implementation
        # Real implementation would use visual-inertial odometry or similar

        # For demonstration, return identity transformation
        # In practice, this would involve:
        # 1. Collecting synchronized data during known motion
        # 2. Using optimization to find best transformation
        # 3. Validating the result

        transform = np.eye(4)  # 4x4 homogeneous transformation matrix

        # Example: camera is 0.1m forward and 0.05m up from IMU
        transform[0:3, 3] = np.array([0.1, 0, 0.05])  # Translation

        return transform

    def _calibrate_lidar_camera(self, lidar_data: List[np.ndarray],
                              camera_data: List[np.ndarray]) -> np.ndarray:
        """Calibrate transformation between LIDAR and camera"""
        # Find corresponding points in both sensors
        # Use point cloud to image projection to find transformation

        # Simplified implementation - in practice would use calibration patterns
        # or natural features that appear in both sensors

        transform = np.eye(4)

        # Example transformation
        transform[0:3, 3] = np.array([0.2, 0, 0.1])  # Translation: 20cm forward, 10cm up

        # Example rotation (90 degree rotation around Z-axis)
        angle = np.pi / 2  # 90 degrees
        transform[0:2, 0:2] = np.array([[np.cos(angle), -np.sin(angle)],
                                       [np.sin(angle), np.cos(angle)]])

        return transform

    def _calibrate_encoder_imu(self, encoder_data: List[np.ndarray],
                              imu_data: List[np.ndarray]) -> np.ndarray:
        """Calibrate relationship between encoder and IMU for joint state estimation"""
        # This involves finding the mounting position of IMU relative to joint axis
        # and the orientation of IMU frame relative to joint frame

        # For a joint with encoder and IMU on the same link:
        # 1. Record encoder positions and IMU orientations during known movements
        # 2. Use optimization to find mounting position and orientation

        # Simplified result
        transform = np.eye(4)
        # Mounting position of IMU relative to joint (example: 5cm along X-axis)
        transform[0:3, 3] = np.array([0.05, 0, 0])

        return transform

    def _calibrate_generic(self, sensor1_data: List[np.ndarray],
                          sensor2_data: List[np.ndarray]) -> np.ndarray:
        """Generic calibration for unknown sensor types"""
        # Use a simple offset calibration as fallback
        if len(sensor1_data) > 0 and len(sensor2_data) > 0:
            avg1 = np.mean(np.array(sensor1_data), axis=0)
            avg2 = np.mean(np.array(sensor2_data), axis=0)

            # Simple offset transformation
            transform = np.eye(len(avg1) + 1)
            transform[0:len(avg1), -1] = avg2 - avg1  # Translation offset

            return transform
        else:
            return np.eye(4)  # Identity transformation

class CalibrationValidator:
    """Validate calibration results"""

    def __init__(self):
        pass

    def validate_imu_calibration(self, imu_driver: IMUDriver, expected_values: Dict) -> Dict:
        """Validate IMU calibration against expected values"""
        # Collect data after calibration
        num_samples = 100
        data_samples = []

        for _ in range(num_samples):
            data = imu_driver.read_data()
            if data and data.validity:
                data_samples.append(data.data)
            time.sleep(0.01)

        if not data_samples:
            return {'valid': False, 'error': 'No data collected'}

        avg_data = np.mean(np.array(data_samples), axis=0)

        results = {
            'accelerometer_valid': self._check_accelerometer(avg_data[0:3], expected_values.get('accel_expected', [0, 0, 9.81])),
            'gyroscope_valid': self._check_gyroscope(avg_data[3:6], expected_values.get('gyro_expected', [0, 0, 0])),
            'magnetometer_valid': self._check_magnetometer(avg_data[6:9], expected_values.get('mag_expected', [22000, 0, 44000]))
        }

        results['overall_valid'] = all(results.values())

        return results

    def _check_accelerometer(self, measured: np.ndarray, expected: np.ndarray, tolerance: float = 0.5) -> bool:
        """Check if accelerometer readings are within tolerance"""
        return np.linalg.norm(measured - expected) < tolerance

    def _check_gyroscope(self, measured: np.ndarray, expected: np.ndarray, tolerance: float = 0.1) -> bool:
        """Check if gyroscope readings are within tolerance"""
        return np.linalg.norm(measured - expected) < tolerance

    def _check_magnetometer(self, measured: np.ndarray, expected: np.ndarray, tolerance: float = 1000) -> bool:
        """Check if magnetometer readings are within tolerance"""
        return np.linalg.norm(measured - expected) < tolerance
```

## 6. Integration with Control Systems

### 6.1 Sensor-Controller Interface

```python
class SensorControllerInterface:
    """Interface between sensor system and robot controller"""

    def __init__(self, fusion_manager: SensorFusionManager):
        self.fusion_manager = fusion_manager
        self.controller_commands = {}
        self.sensor_feedback = {}
        self.safety_limits = {}
        self.emergency_stop = False

    def get_robot_state(self) -> Dict:
        """Get current robot state from sensor fusion"""
        return self.fusion_manager.get_fused_state()

    def get_joint_states(self) -> Dict:
        """Get joint position, velocity, and effort from encoders"""
        # This would interface with encoder data
        joint_states = {}

        # Example implementation - in practice would get from actual encoder sensors
        for sensor_id, sensor_info in self.fusion_manager.sensors.items():
            if sensor_info['type'] == 'encoder':
                if sensor_info['data'] is not None:
                    position = sensor_info['data'][0] if len(sensor_info['data']) > 0 else 0
                    velocity = sensor_info['data'][1] if len(sensor_info['data']) > 1 else 0
                    effort = 0  # Effort would come from torque sensors

                    joint_states[sensor_id] = {
                        'position': position,
                        'velocity': velocity,
                        'effort': effort,
                        'timestamp': sensor_info['last_update']
                    }

        return joint_states

    def get_imu_data(self) -> Dict:
        """Get IMU data for balance and orientation control"""
        imu_data = {}

        for sensor_id, sensor_info in self.fusion_manager.sensors.items():
            if sensor_info['type'] in ['accelerometer', 'gyroscope', 'magnetometer', 'imu']:
                if sensor_info['data'] is not None and len(sensor_info['data']) >= 9:
                    # Extract accelerometer, gyroscope, and magnetometer data
                    accel = sensor_info['data'][0:3]
                    gyro = sensor_info['data'][3:6]
                    mag = sensor_info['data'][6:9]

                    imu_data[sensor_id] = {
                        'linear_acceleration': accel,
                        'angular_velocity': gyro,
                        'magnetic_field': mag,
                        'orientation': self._compute_orientation_from_imu(accel, gyro, mag),
                        'timestamp': sensor_info['last_update']
                    }

        return imu_data

    def _compute_orientation_from_imu(self, accel: np.ndarray, gyro: np.ndarray,
                                    mag: np.ndarray = None) -> np.ndarray:
        """Compute orientation from IMU data using sensor fusion"""
        # Use accelerometer for gravity-based orientation
        # Use gyroscope for rotation rate integration
        # Use magnetometer for absolute heading (if available)

        # Simplified orientation computation
        # In practice, would use more sophisticated fusion algorithm

        # Normalize accelerometer vector to get gravity direction
        gravity_norm = accel / np.linalg.norm(accel) if np.linalg.norm(accel) > 0 else np.array([0, 0, 1])

        # Compute roll and pitch from gravity vector
        pitch = np.arctan2(-gravity_norm[0], np.sqrt(gravity_norm[1]**2 + gravity_norm[2]**2))
        roll = np.arctan2(gravity_norm[1], gravity_norm[2])

        # Yaw from magnetometer if available
        yaw = 0
        if mag is not None:
            # Simplified magnetic heading computation
            # In practice, would need to account for magnetic declination and tilt
            yaw = np.arctan2(mag[1], mag[0])

        # Convert to quaternion
        q = self._euler_to_quaternion(roll, pitch, yaw)

        return q

    def _euler_to_quaternion(self, roll: float, pitch: float, yaw: float) -> np.ndarray:
        """Convert Euler angles to quaternion"""
        cy = np.cos(yaw * 0.5)
        sy = np.sin(yaw * 0.5)
        cp = np.cos(pitch * 0.5)
        sp = np.sin(pitch * 0.5)
        cr = np.cos(roll * 0.5)
        sr = np.sin(roll * 0.5)

        w = cr * cp * cy + sr * sp * sy
        x = sr * cp * cy - cr * sp * sy
        y = cr * sp * cy + sr * cp * sy
        z = cr * cp * sy - sr * sp * cy

        return np.array([w, x, y, z])

    def check_safety_limits(self) -> bool:
        """Check if robot is within safety limits based on sensor data"""
        robot_state = self.get_robot_state()

        # Check position limits
        position = robot_state['position']
        if (np.any(np.abs(position) > 10.0)):  # 10m safety limit
            print("Safety: Position limit exceeded")
            self.emergency_stop = True
            return False

        # Check velocity limits
        velocity = robot_state['velocity']
        if (np.any(np.abs(velocity) > 5.0)):  # 5m/s velocity limit
            print("Safety: Velocity limit exceeded")
            self.emergency_stop = True
            return False

        # Check orientation limits (for balance)
        orientation = robot_state['orientation']
        # Convert quaternion to Euler angles to check tilt
        euler = self._quaternion_to_euler(orientation)
        if abs(euler[0]) > np.pi/3 or abs(euler[1]) > np.pi/3:  # 60 degree tilt limit
            print("Safety: Orientation limit exceeded - possible fall")
            self.emergency_stop = True
            return False

        self.emergency_stop = False
        return True

    def _quaternion_to_euler(self, q: np.ndarray) -> np.ndarray:
        """Convert quaternion to Euler angles (roll, pitch, yaw)"""
        w, x, y, z = q

        # Roll (x-axis rotation)
        sinr_cosp = 2 * (w * x + y * z)
        cosr_cosp = 1 - 2 * (x * x + y * y)
        roll = np.arctan2(sinr_cosp, cosr_cosp)

        # Pitch (y-axis rotation)
        sinp = 2 * (w * y - z * x)
        if np.abs(sinp) >= 1:
            pitch = np.copysign(np.pi / 2, sinp)  # Use 90 degrees if out of range
        else:
            pitch = np.arcsin(sinp)

        # Yaw (z-axis rotation)
        siny_cosp = 2 * (w * z + x * y)
        cosy_cosp = 1 - 2 * (y * y + z * z)
        yaw = np.arctan2(siny_cosp, cosy_cosp)

        return np.array([roll, pitch, yaw])

    def get_safety_status(self) -> Dict:
        """Get overall safety status based on all sensors"""
        return {
            'emergency_stop': self.emergency_stop,
            'position_safe': self._check_position_safety(),
            'velocity_safe': self._check_velocity_safety(),
            'orientation_safe': self._check_orientation_safety(),
            'collision_free': self._check_collision_safety()
        }

    def _check_position_safety(self) -> bool:
        """Check if position is within safe bounds"""
        # Implementation would check against predefined safe workspace
        return True

    def _check_velocity_safety(self) -> bool:
        """Check if velocity is within safe limits"""
        # Implementation would check velocity against limits
        return True

    def _check_orientation_safety(self) -> bool:
        """Check if orientation is safe for humanoid stability"""
        # Implementation would check against balance limits
        return True

    def _check_collision_safety(self) -> bool:
        """Check for collision using range sensors"""
        # Implementation would check range sensor data for obstacles
        return True
```

## 7. Performance Optimization

### 7.1 Efficient Data Structures

```python
import numpy as np
from collections import deque
import ctypes
from numba import jit, cuda

class EfficientSensorBuffer:
    """Optimized buffer for high-frequency sensor data"""

    def __init__(self, buffer_size: int, data_dim: int, dtype=np.float32):
        self.buffer_size = buffer_size
        self.data_dim = data_dim
        self.dtype = dtype

        # Pre-allocated circular buffer using numpy array
        self.buffer = np.zeros((buffer_size, data_dim), dtype=dtype)
        self.timestamps = np.zeros(buffer_size, dtype=np.float64)
        self.validity = np.zeros(buffer_size, dtype=bool)

        self.head = 0  # Index of oldest data
        self.tail = 0  # Index of newest data
        self.count = 0  # Number of valid entries
        self.lock = threading.Lock()

    def add_data(self, data: np.ndarray, timestamp: float, valid: bool = True):
        """Add new sensor data to buffer (thread-safe)"""
        with self.lock:
            # Store data at tail position
            self.buffer[self.tail] = data
            self.timestamps[self.tail] = timestamp
            self.validity[self.tail] = valid

            # Update tail pointer
            self.tail = (self.tail + 1) % self.buffer_size

            # If buffer is full, advance head
            if self.count == self.buffer_size:
                self.head = (self.head + 1) % self.buffer_size
            else:
                self.count += 1

    def get_recent_data(self, n: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Get n most recent data points"""
        with self.lock:
            if n > self.count:
                n = self.count

            if n <= 0:
                return np.array([]), np.array([]), np.array([])

            # Calculate start index
            start_idx = (self.tail - n) % self.buffer_size

            if start_idx < self.tail:
                # Data is contiguous
                data = self.buffer[start_idx:self.tail]
                timestamps = self.timestamps[start_idx:self.tail]
                validity = self.validity[start_idx:self.tail]
            else:
                # Data wraps around
                data1 = self.buffer[start_idx:]
                data2 = self.buffer[:self.tail]
                data = np.vstack([data1, data2])

                ts1 = self.timestamps[start_idx:]
                ts2 = self.timestamps[:self.tail]
                timestamps = np.concatenate([ts1, ts2])

                v1 = self.validity[start_idx:]
                v2 = self.validity[:self.tail]
                validity = np.concatenate([v1, v2])

            return data, timestamps, validity

    def get_filtered_data(self, time_window: float, current_time: float) -> Tuple[np.ndarray, np.ndarray]:
        """Get data within a specific time window"""
        with self.lock:
            valid_indices = []

            for i in range(self.count):
                idx = (self.head + i) % self.buffer_size
                if current_time - self.timestamps[idx] <= time_window and self.validity[idx]:
                    valid_indices.append(idx)

            if not valid_indices:
                return np.array([]), np.array([])

            data = self.buffer[valid_indices]
            timestamps = self.timestamps[valid_indices]

            return data, timestamps

class OptimizedFusionCore:
    """Optimized core for sensor fusion computations"""

    def __init__(self):
        # Pre-allocate arrays for common computations
        self.state_vector = np.zeros(13, dtype=np.float64)  # Position, velocity, orientation, angular velocity
        self.covariance_matrix = np.eye(13, dtype=np.float64)
        self.jacobian_matrix = np.zeros((9, 13), dtype=np.float64)  # Measurement x state Jacobian
        self.kalman_gain = np.zeros((13, 9), dtype=np.float64)
        self.innovation = np.zeros(9, dtype=np.float64)
        self.innovation_cov = np.zeros((9, 9), dtype=np.float64)

    @staticmethod
    @jit(nopython=True)
    def fast_matrix_multiply(A, B):
        """Fast matrix multiplication using Numba JIT"""
        rows_A, cols_A = A.shape
        rows_B, cols_B = B.shape
        assert cols_A == rows_B

        C = np.zeros((rows_A, cols_B))
        for i in range(rows_A):
            for j in range(cols_B):
                for k in range(cols_A):
                    C[i, j] += A[i, k] * B[k, j]
        return C

    def predict_state(self, dt: float, control_input: np.ndarray = None):
        """Optimized state prediction step"""
        # Use pre-allocated arrays to avoid memory allocation
        new_state = self.state_vector.copy()

        # Position update: p_new = p_old + v*dt
        new_state[0:3] = self.state_vector[0:3] + self.state_vector[3:6] * dt

        # Orientation update using quaternion integration
        q = self.state_vector[6:10]  # Current orientation quaternion
        omega = self.state_vector[10:13]  # Angular velocity

        # Quaternion derivative: dq/dt = 0.5 * omega_quat * q
        omega_quat = np.array([0.0, omega[0], omega[1], omega[2]], dtype=np.float64)
        q_dot = self._quaternion_multiply_fast(omega_quat, q) * 0.5

        # Integrate: q_new = q_old + q_dot*dt
        new_q = q + q_dot * dt
        # Normalize quaternion
        norm = np.sqrt(np.sum(new_q * new_q))
        if norm > 0:
            new_q = new_q / norm

        new_state[6:10] = new_q
        new_state[10:13] = self.state_vector[10:13]  # Angular velocity update depends on dynamics

        # Apply control input if provided
        if control_input is not None and len(control_input) >= 6:
            # Apply control to linear and angular accelerations
            new_state[3:6] += control_input[0:3] * dt  # Linear acceleration
            new_state[10:13] += control_input[3:6] * dt  # Angular acceleration

        self.state_vector = new_state

    @staticmethod
    @jit(nopython=True)
    def _quaternion_multiply_fast(q1, q2):
        """Fast quaternion multiplication using Numba"""
        w1, x1, y1, z1 = q1[0], q1[1], q1[2], q1[3]
        w2, x2, y2, z2 = q2[0], q2[1], q2[2], q2[3]

        w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2
        x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2
        y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2
        z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2

        return np.array([w, x, y, z])

class ParallelSensorProcessor:
    """Process multiple sensors in parallel using multiprocessing"""

    def __init__(self, num_processes: int = None):
        self.num_processes = num_processes or mp.cpu_count()
        self.process_pool = ProcessPoolExecutor(max_workers=self.num_processes)
        self.futures = {}

    def process_sensor_batch(self, sensor_data_batch: Dict[str, List[SensorData]]) -> Dict[str, List]:
        """Process a batch of sensor data in parallel"""
        results = {}

        # Submit processing tasks for each sensor type
        for sensor_id, data_list in sensor_data_batch.items():
            future = self.process_pool.submit(
                self._process_sensor_data_parallel,
                sensor_id, data_list
            )
            self.futures[sensor_id] = future

        # Collect results
        for sensor_id, future in self.futures.items():
            try:
                results[sensor_id] = future.result(timeout=1.0)  # 1 second timeout
            except Exception as e:
                print(f"Error processing {sensor_id}: {e}")
                results[sensor_id] = []

        return results

    def _process_sensor_data_parallel(self, sensor_id: str, data_list: List[SensorData]) -> List:
        """Process sensor data in parallel"""
        processed_data = []

        for sensor_data in data_list:
            # Apply sensor-specific processing
            if 'imu' in sensor_id.lower():
                processed = self._process_imu_data(sensor_data)
            elif 'encoder' in sensor_id.lower():
                processed = self._process_encoder_data(sensor_data)
            elif 'camera' in sensor_id.lower():
                processed = self._process_camera_data(sensor_data)
            else:
                processed = sensor_data.data  # Default: pass through

            processed_data.append(processed)

        return processed_data

    def _process_imu_data(self, sensor_data: SensorData) -> np.ndarray:
        """Process IMU data - apply bias correction and unit conversion"""
        raw_data = sensor_data.data

        # Example processing: bias correction, unit conversion
        if len(raw_data) >= 9:  # accel (3) + gyro (3) + mag (3)
            accel = raw_data[0:3] - np.array([0.1, -0.05, 0.02])  # Apply bias correction
            gyro = raw_data[3:6] - np.array([0.01, -0.02, 0.005])
            mag = raw_data[6:9] - np.array([50, -30, 100])  # Magnetometer bias

            return np.concatenate([accel, gyro, mag])

        return raw_data

    def _process_encoder_data(self, sensor_data: SensorData) -> np.ndarray:
        """Process encoder data - apply resolution conversion and filtering"""
        raw_data = sensor_data.data

        # Example: convert raw counts to radians and apply velocity filtering
        if len(raw_data) >= 2:  # position, velocity
            position = raw_data[0] * (2 * np.pi / 4096)  # Convert to radians (assuming 12-bit encoder)
            velocity = raw_data[1]  # Already in appropriate units

            return np.array([position, velocity])

        return raw_data

    def _process_camera_data(self, sensor_data: SensorData) -> np.ndarray:
        """Process camera data - placeholder for image processing"""
        # In practice, this would involve feature extraction, object detection, etc.
        # For now, just return the raw data structure
        return sensor_data.data
```

## 8. Validation and Testing

### 8.1 Sensor Validation Framework

```python
class SensorValidationFramework:
    """Framework for validating sensor system performance"""

    def __init__(self):
        self.validation_results = {}
        self.metrics = {}

    def validate_sensor_accuracy(self, sensor_driver: SensorDriver,
                               reference_data: List[Tuple[float, np.ndarray]]) -> Dict:
        """Validate sensor accuracy against reference data"""
        test_results = {
            'sensor_id': sensor_driver.sensor_id,
            'accuracy_metrics': {},
            'precision_metrics': {},
            'reliability_metrics': {}
        }

        # Collect sensor data synchronized with reference
        collected_data = []
        for ref_time, ref_value in reference_data:
            # Wait for sensor to be ready
            time.sleep(0.01)  # Small delay for synchronization

            sensor_data = sensor_driver.read_data()
            if sensor_data and sensor_data.validity:
                collected_data.append((sensor_data.timestamp, sensor_data.data))

        if not collected_data:
            test_results['valid'] = False
            test_results['error'] = 'No valid sensor data collected'
            return test_results

        # Calculate accuracy metrics
        errors = []
        for i, ((meas_time, meas_value), (ref_time, ref_value)) in enumerate(zip(collected_data, reference_data)):
            if len(meas_value) == len(ref_value):
                error = np.linalg.norm(meas_value - ref_value)
                errors.append(error)

        if errors:
            test_results['accuracy_metrics'] = {
                'rmse': np.sqrt(np.mean(np.array(errors)**2)),
                'max_error': np.max(errors),
                'mean_error': np.mean(errors),
                'std_error': np.std(errors)
            }

        test_results['valid'] = len(errors) > 0

        return test_results

    def validate_sensor_timing(self, sensor_driver: SensorDriver,
                             expected_rate: float, test_duration: float = 10.0) -> Dict:
        """Validate sensor timing and data rate"""
        start_time = time.time()
        timestamps = []

        while time.time() - start_time < test_duration:
            data = sensor_driver.read_data()
            if data and data.validity:
                timestamps.append(data.timestamp)

        if len(timestamps) < 2:
            return {
                'valid': False,
                'error': 'Insufficient data points for timing analysis'
            }

        # Calculate actual rate
        actual_rate = len(timestamps) / (timestamps[-1] - timestamps[0]) if len(timestamps) > 1 else 0

        # Calculate timing jitter
        time_diffs = np.diff(timestamps)
        jitter = np.std(time_diffs) if len(time_diffs) > 1 else 0

        return {
            'expected_rate': expected_rate,
            'actual_rate': actual_rate,
            'rate_error': abs(actual_rate - expected_rate) / expected_rate * 100 if expected_rate > 0 else 0,
            'timing_jitter': jitter,
            'data_points': len(timestamps),
            'valid': abs(actual_rate - expected_rate) / expected_rate < 0.1 if expected_rate > 0 else True  # 10% tolerance
        }

    def validate_sensor_reliability(self, sensor_driver: SensorDriver,
                                  test_duration: float = 60.0) -> Dict:
        """Validate sensor reliability over time"""
        start_time = time.time()
        total_readings = 0
        successful_readings = 0
        errors = []

        while time.time() - start_time < test_duration:
            try:
                data = sensor_driver.read_data()
                total_readings += 1

                if data and data.validity:
                    successful_readings += 1
                else:
                    errors.append('Invalid data')

            except Exception as e:
                errors.append(str(e))
                total_readings += 1

        reliability = successful_readings / total_readings if total_readings > 0 else 0

        return {
            'total_readings': total_readings,
            'successful_readings': successful_readings,
            'reliability': reliability,
            'error_rate': 1 - reliability,
            'errors': errors,
            'valid': reliability > 0.95  # 95% reliability threshold
        }

    def validate_fusion_performance(self, fusion_manager: SensorFusionManager,
                                  test_scenarios: List[Dict]) -> Dict:
        """Validate multi-sensor fusion performance"""
        fusion_results = {
            'scenario_results': [],
            'overall_performance': {}
        }

        for scenario in test_scenarios:
            # Set up test scenario
            scenario_result = self._run_fusion_scenario(fusion_manager, scenario)
            fusion_results['scenario_results'].append(scenario_result)

        # Aggregate overall performance
        if fusion_results['scenario_results']:
            all_accuracies = [r['accuracy'] for r in fusion_results['scenario_results'] if 'accuracy' in r]
            if all_accuracies:
                fusion_results['overall_performance'] = {
                    'mean_accuracy': np.mean(all_accuracies),
                    'std_accuracy': np.std(all_accuracies),
                    'min_accuracy': np.min(all_accuracies),
                    'max_accuracy': np.max(all_accuracies)
                }

        return fusion_results

    def _run_fusion_scenario(self, fusion_manager: SensorFusionManager, scenario: Dict) -> Dict:
        """Run a single fusion validation scenario"""
        # This would involve:
        # 1. Setting up specific sensor conditions
        # 2. Running fusion algorithm
        # 3. Comparing results to expected values
        # 4. Recording performance metrics

        # Placeholder implementation
        return {
            'scenario_name': scenario.get('name', 'unknown'),
            'accuracy': 0.98,  # Placeholder value
            'processing_time': 0.002,  # 2ms average processing time
            'valid': True
        }

class SensorHealthMonitor:
    """Monitor sensor health and detect failures in real-time"""

    def __init__(self, check_interval: float = 1.0):
        self.check_interval = check_interval
        self.sensors = {}
        self.health_status = {}
        self.failure_history = {}
        self.is_monitoring = False
        self.monitor_thread = None

    def add_sensor(self, sensor_id: str, sensor_driver: SensorDriver):
        """Add a sensor to health monitoring"""
        self.sensors[sensor_id] = sensor_driver
        self.health_status[sensor_id] = {
            'last_check': 0,
            'last_value': None,
            'last_timestamp': 0,
            'health_score': 1.0,
            'failure_count': 0,
            'status': 'healthy'
        }
        self.failure_history[sensor_id] = deque(maxlen=100)

    def start_monitoring(self):
        """Start continuous health monitoring"""
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()

    def stop_monitoring(self):
        """Stop health monitoring"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()

    def _monitor_loop(self):
        """Main monitoring loop"""
        while self.is_monitoring:
            current_time = time.time()

            for sensor_id, sensor_driver in self.sensors.items():
                self._check_sensor_health(sensor_id, sensor_driver, current_time)

            time.sleep(self.check_interval)

    def _check_sensor_health(self, sensor_id: str, sensor_driver: SensorDriver, current_time: float):
        """Check health of a single sensor"""
        try:
            # Read sensor data
            data = sensor_driver.read_data()

            if data is None:
                # Sensor communication failure
                self._update_failure_status(sensor_id, 'communication_error', current_time)
                return

            if not data.validity:
                # Data validity failure
                self._update_failure_status(sensor_id, 'data_invalid', current_time)
                return

            # Check for reasonable values (basic plausibility)
            if not self._check_value_plausibility(sensor_id, data.data):
                self._update_failure_status(sensor_id, 'value_out_of_range', current_time)
                return

            # Check for stuck values (no change over time)
            last_value = self.health_status[sensor_id]['last_value']
            if last_value is not None and np.array_equal(data.data, last_value):
                # Check if this is persisting
                time_since_change = current_time - self.health_status[sensor_id]['last_timestamp']
                if time_since_change > 5.0:  # 5 seconds without change
                    self._update_failure_status(sensor_id, 'stuck_value', current_time)
                    return

            # Sensor is healthy
            self.health_status[sensor_id].update({
                'last_check': current_time,
                'last_value': data.data.copy(),
                'last_timestamp': data.timestamp,
                'health_score': min(1.0, self.health_status[sensor_id]['health_score'] + 0.01),  # Slight recovery
                'status': 'healthy'
            })

            # Record in failure history
            self.failure_history[sensor_id].append(('ok', current_time))

        except Exception as e:
            self._update_failure_status(sensor_id, f'exception: {str(e)}', current_time)

    def _check_value_plausibility(self, sensor_id: str, values: np.ndarray) -> bool:
        """Check if sensor values are within reasonable bounds"""
        # This would be sensor-specific
        # For example, IMU values should be within physical limits
        # Encoder values should not change too rapidly

        if 'imu' in sensor_id.lower():
            # IMU values should be reasonable (not NaN, not extremely large)
            if np.any(np.isnan(values)) or np.any(np.abs(values) > 100):
                return False
        elif 'encoder' in sensor_id.lower():
            # Encoder values should be finite
            if np.any(np.isnan(values)) or np.any(np.isinf(values)):
                return False

        return True

    def _update_failure_status(self, sensor_id: str, failure_type: str, current_time: float):
        """Update failure status for a sensor"""
        self.health_status[sensor_id].update({
            'last_check': current_time,
            'health_score': max(0.0, self.health_status[sensor_id]['health_score'] - 0.1),  # Reduce health score
            'failure_count': self.health_status[sensor_id]['failure_count'] + 1,
            'status': 'degraded' if self.health_status[sensor_id]['health_score'] > 0.5 else 'failed'
        })

        # Record failure in history
        self.failure_history[sensor_id].append((failure_type, current_time))

    def get_health_report(self) -> Dict:
        """Get overall health report"""
        return {
            'sensor_health': self.health_status.copy(),
            'failure_counts': {sid: status['failure_count'] for sid, status in self.health_status.items()},
            'overall_status': self._compute_overall_status()
        }

    def _compute_overall_status(self) -> str:
        """Compute overall system health status"""
        healthy_count = sum(1 for status in self.health_status.values() if status['status'] == 'healthy')
        total_count = len(self.health_status)

        if healthy_count == total_count:
            return 'all_healthy'
        elif healthy_count >= total_count * 0.8:  # 80% healthy
            return 'mostly_healthy'
        elif healthy_count >= total_count * 0.5:  # 50% healthy
            return 'degraded'
        else:
            return 'critical'
```

## 9. Practical Examples and Case Studies

### 9.1 Humanoid Robot Sensor Integration Example

```python
class HumanoidSensorSystem:
    """Complete sensor system implementation for a humanoid robot"""

    def __init__(self, robot_config: Dict):
        self.robot_config = robot_config
        self.sensors = {}
        self.drivers = {}
        self.fusion_manager = SensorFusionManager()
        self.pipeline = SensorDataPipeline()
        self.calibrator = SensorCalibrator()
        self.health_monitor = SensorHealthMonitor()
        self.controller_interface = SensorControllerInterface(self.fusion_manager)

        # Initialize sensor system based on robot configuration
        self._setup_sensors()

    def _setup_sensors(self):
        """Setup all sensors based on robot configuration"""
        for sensor_info in self.robot_config.get('sensors', []):
            sensor_id = sensor_info['id']
            sensor_type = sensor_info['type']
            config = sensor_info['config']

            # Create appropriate driver
            if sensor_type == 'encoder':
                driver = EncoderDriver(sensor_id, config)
            elif sensor_type == 'imu':
                driver = IMUDriver(sensor_id, config)
            elif sensor_type == 'force_torque':
                driver = self._create_force_torque_driver(sensor_id, config)
            elif sensor_type == 'camera':
                driver = self._create_camera_driver(sensor_id, config)
            else:
                print(f"Unknown sensor type: {sensor_type}")
                continue

            # Connect driver
            if driver.connect():
                self.drivers[sensor_id] = driver
                self.sensors[sensor_id] = {
                    'type': sensor_type,
                    'driver': driver,
                    'config': config
                }

                # Register with fusion manager
                self.fusion_manager.register_sensor(sensor_id, sensor_type)

                # Add to pipeline
                self.pipeline.add_sensor_buffer(sensor_id)

                # Add to health monitor
                self.health_monitor.add_sensor(sensor_id, driver)

                print(f"Successfully initialized sensor: {sensor_id}")
            else:
                print(f"Failed to connect sensor: {sensor_id}")

    def _create_force_torque_driver(self, sensor_id: str, config: Dict):
        """Create force/torque sensor driver"""
        # This would be implemented based on specific F/T sensor type
        # For example, ATI, Schunk, or custom F/T sensors
        class ForceTorqueDriver(SensorDriver):
            def __init__(self, sensor_id: str, config: Dict):
                super().__init__(sensor_id, config)
                # Initialize F/T sensor interface

            def connect(self) -> bool:
                # Implementation for connecting to F/T sensor
                return True

            def read_data(self) -> Optional[SensorData]:
                # Read F/T data (6-axis: Fx, Fy, Fz, Tx, Ty, Tz)
                return SensorData(
                    timestamp=time.time(),
                    data=np.random.rand(6) * 0.1,  # Placeholder
                    validity=True,
                    source_id=self.sensor_id
                )

            def disconnect(self) -> bool:
                # Disconnect from F/T sensor
                return True

        return ForceTorqueDriver(sensor_id, config)

    def _create_camera_driver(self, sensor_id: str, config: Dict):
        """Create camera driver"""
        # This would interface with actual camera hardware
        # Using OpenCV, ROS, or other camera interfaces
        class CameraDriver(SensorDriver):
            def __init__(self, sensor_id: str, config: Dict):
                super().__init__(sensor_id, config)
                # Initialize camera interface

            def connect(self) -> bool:
                # Implementation for connecting to camera
                return True

            def read_data(self) -> Optional[SensorData]:
                # For cameras, we might return feature data or processed information
                # rather than raw image data
                return SensorData(
                    timestamp=time.time(),
                    data=np.array([0.0]),  # Placeholder
                    validity=True,
                    source_id=self.sensor_id
                )

            def disconnect(self) -> bool:
                # Disconnect from camera
                return True

        return CameraDriver(sensor_id, config)

    def calibrate_system(self):
        """Calibrate the entire sensor system"""
        print("Starting system-wide sensor calibration...")

        # Calibrate individual sensors
        for sensor_id, sensor_info in self.sensors.items():
            if sensor_info['type'] == 'imu':
                print(f"Calibrating IMU: {sensor_id}")
                try:
                    params = self.calibrator.calibrate_imu(sensor_info['driver'])
                    self.calibrator.save_calibration(params, f"{sensor_id}_calibration.json")
                    print(f"IMU {sensor_id} calibrated successfully")
                except Exception as e:
                    print(f"IMU {sensor_id} calibration failed: {e}")

            elif sensor_info['type'] == 'encoder':
                print(f"Calibrating encoder: {sensor_id}")
                try:
                    params = self.calibrator.calibrate_encoder(sensor_info['driver'])
                    print(f"Encoder {sensor_id} calibrated successfully")
                except Exception as e:
                    print(f"Encoder {sensor_id} calibration failed: {e}")

        # Perform multi-sensor calibration
        print("Performing multi-sensor calibration...")
        self._perform_multisensor_calibration()

        print("System calibration completed")

    def _perform_multisensor_calibration(self):
        """Perform calibration between different sensor types"""
        # Example: calibrate IMU to base frame, encoders to kinematic model, etc.
        # This would involve collecting synchronized data during known motions
        multicalibrator = MultiSensorCalibrator()

        # Calibrate IMU mounting position relative to robot base
        # This is typically done with the robot in known orientations
        print("Multi-sensor calibration completed")

    def start_operation(self):
        """Start the sensor system operation"""
        print("Starting sensor system operation...")

        # Start health monitoring
        self.health_monitor.start_monitoring()

        # Start data pipeline
        self.pipeline.start_pipeline()

        # Start sensor reading threads
        self._start_sensor_reading()

        print("Sensor system operational")

    def _start_sensor_reading(self):
        """Start reading from all sensors in background threads"""
        for sensor_id, sensor_info in self.sensors.items():
            thread = threading.Thread(
                target=self._sensor_reading_loop,
                args=(sensor_id, sensor_info['driver']),
                daemon=True
            )
            thread.start()

    def _sensor_reading_loop(self, sensor_id: str, driver: SensorDriver):
        """Reading loop for a single sensor"""
        rate = self.sensors[sensor_id]['config'].get('rate', 100)  # Default 100Hz
        period = 1.0 / rate

        while True:
            try:
                data = driver.read_data()
                if data:
                    # Add to pipeline
                    self.pipeline.add_sensor_data(sensor_id, data)

                time.sleep(period)

            except Exception as e:
                print(f"Error reading sensor {sensor_id}: {e}")
                time.sleep(0.1)  # Brief pause before retry

    def get_robot_state(self) -> Dict:
        """Get current robot state from sensor fusion"""
        return self.controller_interface.get_robot_state()

    def get_safety_status(self) -> Dict:
        """Get safety status from all sensors"""
        return self.controller_interface.get_safety_status()

    def stop_operation(self):
        """Stop the sensor system operation"""
        print("Stopping sensor system...")

        # Stop all threads
        self.pipeline.stop_pipeline()
        self.health_monitor.stop_monitoring()

        # Disconnect all sensors
        for sensor_id, sensor_info in self.sensors.items():
            try:
                sensor_info['driver'].disconnect()
            except Exception as e:
                print(f"Error disconnecting {sensor_id}: {e}")

        print("Sensor system stopped")

# Example usage
def example_humanoid_sensor_system():
    """Example of setting up a humanoid sensor system"""

    # Robot configuration
    robot_config = {
        'name': 'ExampleHumanoid',
        'sensors': [
            {
                'id': 'imu_torso',
                'type': 'imu',
                'config': {
                    'interface': 'i2c',
                    'address': 0x68,
                    'bus': 1,
                    'sample_rate': 200
                }
            },
            {
                'id': 'encoder_left_hip',
                'type': 'encoder',
                'config': {
                    'interface': 'spi',
                    'resolution': 4096,
                    'is_absolute': True,
                    'rate': 1000
                }
            },
            {
                'id': 'encoder_right_hip',
                'type': 'encoder',
                'config': {
                    'interface': 'spi',
                    'resolution': 4096,
                    'is_absolute': True,
                    'rate': 1000
                }
            },
            # Add more sensors as needed...
        ]
    }

    # Create and initialize sensor system
    sensor_system = HumanoidSensorSystem(robot_config)

    # Calibrate the system
    sensor_system.calibrate_system()

    # Start operation
    sensor_system.start_operation()

    # Example: get robot state
    state = sensor_system.get_robot_state()
    print(f"Robot state: {state}")

    # Example: check safety
    safety = sensor_system.get_safety_status()
    print(f"Safety status: {safety}")

    # Let it run for a bit
    time.sleep(5)

    # Stop operation
    sensor_system.stop_operation()

if __name__ == "__main__":
    example_humanoid_sensor_system()
```

## Conclusion

The practical implementation of sensor systems for humanoid robots requires careful attention to hardware interfaces, real-time processing, data fusion, and system reliability. The implementations provided in this section demonstrate how to create robust sensor systems that can handle the demanding requirements of humanoid robot applications.

Key implementation considerations include efficient data structures for high-frequency sensor data, optimized algorithms for real-time processing, proper calibration procedures for accuracy, and comprehensive validation frameworks for reliability. The modular design of these systems allows for adaptation to different robot architectures and application requirements.

Successful implementation requires iterative refinement, with continuous validation and adjustment based on real-world performance. The combination of accurate sensing, efficient processing, and robust integration enables humanoid robots to achieve the perception capabilities required for safe and effective human-robot interaction.